{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facebook Stock Event Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*A few weeks ago Facebook's stock skyrocketed after they announced the fourth-quarter earnings on the 30th of January 2019. Despite all privacy scandals and criticism in the media recently, the tech unicorn proved investors wrong: stock prices exceeded the 170 dollar mark after a long period of decline. Figure 1 illustrates the financial consequences of this event as compared to overall industry market growth (NASDAQ).*\n",
    "\n",
    "*In this assignment we apply the event study method to demonstrate that stock returns on the 30th and 31th of January can be regarded as abnormal. This method assumes that * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Facebook Stock](FB_stock.png)\n",
    "**Figure 1**: Facebook (dark blue) vs NASDAQ (light blue) stock price growth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect Facebook stock data for the last 2 years (IEX Trading API)\n",
    "import requests, pandas as pd\n",
    "\n",
    "def get_stock(stock_symbol):\n",
    "    r = requests.get('https://api.iextrading.com/1.0/stock/' + stock_symbol + '/chart/2y')\n",
    "    result = r.json()\n",
    "    return pd.DataFrame(list({pd.to_datetime(date['date']): date['close'] for date in result}.items()), columns=['date', 'stock']) \n",
    "\n",
    "fb = get_stock('fb')\n",
    "ndaq = get_stock('ndaq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define stock returns\n",
    "def stock_returns(df): \n",
    "    for row in range(1, len(df)):\n",
    "        df.loc[row, \"stock_return\"] = (df.loc[row, \"stock\"] - df.loc[row-1, \"stock\"]) / df.loc[row-1, \"stock\"]\n",
    "        df.loc[row, \"actual_stock_return\"] = (df.loc[row, \"stock\"] - df.loc[row-1, \"stock\"]) - 1\n",
    "    return df\n",
    "\n",
    "fb = stock_returns(fb)\n",
    "ndaq = stock_returns(ndaq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run simple ols model on stock returns (14th of February 2017 to 29th of January 2019)\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "end_date = '2019-01-29'\n",
    "\n",
    "X = ndaq.loc[1:fb[fb.date == end_date].index[0], ['stock_return']] \n",
    "y = fb.loc[1:fb[fb.date == end_date].index[0], ['stock_return']]\n",
    "\n",
    "X2 = sm.add_constant(X)\n",
    "est = sm.OLS(y, X2.astype(float))\n",
    "est2 = est.fit()\n",
    "print(est2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate expected Facebook returns\n",
    "df_merged = pd.merge(fb, ndaq, left_on = 'date', right_on = 'date', suffixes=('_fb', '_ndaq'))\n",
    "df_merged['expected_return_fb'] = est2.params[0] + est2.params[1] * df_merged['actual_stock_return_ndaq']\n",
    "df_merged['abnormal_return_fb'] = df_merged['actual_stock_return_fb'] - df_merged['expected_return_fb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 5 dates positive abnormal returns \n",
    "df_merged[['date', 'abnormal_return_fb']].sort_values(by='abnormal_return_fb', ascending=False).head()\n",
    "# note that the 31st of January 2019 has the highest abnormal return!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 5 dates negative abnormal returns \n",
    "df_merged[['date', 'abnormal_return_fb']].sort_values(by='abnormal_return_fb', ascending=True).head()\n",
    "# this CNBC article explains why the 26th of June was Facebook's worst day ever: https://www.cnbc.com/2018/07/26/facebook-is-on-pace-for-its-worst-day-ever.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a more detailed looks suggests a 2-day window would be most appropriate (30th and 31st of January)\n",
    "df_merged.loc[491:498, ['date', 'abnormal_return_fb']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate cumulative abornomal returns (CAR)\n",
    "CAR = df_merged.loc[df_merged.date == '2019-01-30', 'abnormal_return_fb'].item() + df_merged.loc[df_merged.date == '2019-01-31', 'abnormal_return_fb'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate standardized abnormal returns (SCAR)\n",
    "import numpy as np\n",
    "\n",
    "event_window_length = 2\n",
    "var_e = np.var(est2.resid)\n",
    "\n",
    "SCAR = (CAR/100) / (event_window_length * var_e)**.5\n",
    "\n",
    "print(\"All in all, we can conclude that abnormal returns in event period are \" + str(round(SCAR,1)) + \" standard deviations from estimation period abnormal returns. Hence, the publication of fourth-quarter results on January 30th 2019 had a significant positive effect on Facebook's stock price.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
